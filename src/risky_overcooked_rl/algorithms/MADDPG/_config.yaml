######## RIGHT ######
device: None

env:
  layout: 'risky_coordination_ring'
  p_slip: 0.0
  horizon: 400

  seed: 42
  num_episodes: 5000
  num_warmup_episodes: 25
  eval_episode_freq: 10
  num_eval_episodes: 1
  replay_buffer_capacity: 1e6

  exploration_noise:
    init_scale: 1.0 # change
    exp_decay: 1 # change
    final_scale: 0.05

  reward_shaping:
    init_scale: 1.0
    exp_decay: 4
    final_scale: 0.0
    perc_delay: 0.0 # percentage of total episodes to delay reward shaping decay



agent:
  name: 'MADDPG Self-Play'
  num_agents: 2
  discrete_action_space: True
  batch_size: 256
  gamma: 0.95
#  lr: 5e-5
  tau: 0.0005
  hidden_dim: 256

  device: None # to be specified later
  obs_dim: None  # to be specified later
  action_dim: None  # to be specified later
#  critic:
#    input_dim: None  # to be specified later

  critic:
    lr: 5e-5
    input_dim: None  # to be specified later
  actor:
    lr: 5e-6       # typically ~ critic.lr * 0.1
    input_dim: None  # to be specified later

  'cpt_params': # Default rational CPT parameters
    'b': 0.0      # reference point
    'lam': 1.0    # loss aversion
    'eta_p': 1.0  # diminishing gain sensitivity
    'eta_n': 1.0  # diminishing loss sensitivity
    'delta_p': 1.0 # s-shaped probability estimation bias for gains
    'delta_n': 1.0 # s-shaped probability estimation bias for losses





####### LEFT #######
#device: None
#
#env:
#  layout: 'risky_coordination_ring'
#  p_slip: 0.0
#  horizon: 400
#
#  seed: 42
#  num_episodes: 5000
#  num_warmup_episodes: 25
#  eval_episode_freq: 10
#  num_eval_episodes: 1
#  replay_buffer_capacity: 1e6 # right
#
#  exploration_noise:
#    init_scale: 0.75 # right
#    exp_decay: 4
#    final_scale: 0.05
#
#  reward_shaping:
#    init_scale: 1.0
#    exp_decay: 4
#    final_scale: 0.0
#
#
#
#agent:
#  name: 'MADDPG Self-Play'
#  num_agents: 2
#  discrete_action_space: True
#  batch_size: 256
#  gamma: 0.95
##  lr: 5e-5
#  tau: 0.0005
#  hidden_dim: 256
#
#  device: None # to be specified later
#  obs_dim: None  # to be specified later
#  action_dim: None  # to be specified later
##  critic:
##    input_dim: None  # to be specified later
#
#  critic:
#    lr: 5e-5
#    input_dim: None  # to be specified later
#  actor:
#    lr: 5e-6       # typically ~ critic.lr * 0.1
#    input_dim: None  # to be specified later
#
#
#
